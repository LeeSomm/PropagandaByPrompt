{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of AIâ€‘Generated News Articles for Linguistic Strategy Detection\n",
    "\n",
    "This notebook runs SHAP (SHapley Additive exPlanations) analysis on LightGBM models trained in \"Propaganda by Prompt: Tracing Hidden Linguistic Strategies in Large Language Models.\" \n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment Setup](#1-environment-setup)\n",
    "2. [Model Configuration](#2-model-configuration)\n",
    "3. [Data Preparation](#3-data-preparation)\n",
    "4. [Model Performance Analysis](#4-model-performance-analysis)\n",
    "5. [SHAP Analysis](#5-shap-analysis)\n",
    "   - [Summary Plots](#summary-plots)\n",
    "   - [Feature Dependence Analysis](#feature-dependence-analysis)\n",
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "This notebook requires several Python packages for machine learning, data analysis, and visualization. Install dependencies using:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shap\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "from sklearn import model_selection\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "The notebook supports analysis of multiple LightGBM models trained on different subsets of data:\n",
    "\n",
    "- **Combined Models**: Analyze all topics together\n",
    "- **Topic-specific Models**: Separate models for climate change, COVID-19, the Capitol riot, and LGBT topics\n",
    "- **Model Variants**: \n",
    "  - Stored in the models directory\n",
    "  - With/without punctuation features\n",
    "  - Different GPT versions (GPT-3.5, GPT-4o, GPT-4.1)\n",
    "\n",
    "Each model configuration includes:\n",
    "- SQL query for data selection\n",
    "- Target variable specification\n",
    "- Feature set configuration (with/without punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your configuration dictionary\n",
    "model_configs = {\n",
    "    \"models/LGBM_Combined_DetectHumanProp.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"human\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_Combined_DetectAI_GPT35_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model IN (\"gpt-3.5-turbo\", \"human\")',\n",
    "        \"target_variable\": \"AI\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_Combined_DetectAIProp_GPT35.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_Combined_DetectAIProp_GPT35_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_Combined_DetectAIProp_GPT4o.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_Combined_DetectAIProp_GPT4o_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_Combined_DetectAIProp_GPT41.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_Combined_DetectAIProp_GPT41_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_climate_DetectAIProp_GPT35.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\" AND topic LIKE \"climate\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_climate_DetectAIProp_GPT35_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\" AND topic LIKE \"climate\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_climate_DetectAIProp_GPT4o.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\" AND topic LIKE \"climate\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_climate_DetectAIProp_GPT4o_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\" AND topic LIKE \"climate\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_climate_DetectAIProp_GPT41.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\" AND topic LIKE \"climate\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_climate_DetectAIProp_GPT41_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\" AND topic LIKE \"climate\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_covid_DetectAIProp_GPT35.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\" AND topic LIKE \"covid\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_covid_DetectAIProp_GPT35_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\" AND topic LIKE \"covid\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_covid_DetectAIProp_GPT4o.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\" AND topic LIKE \"covid\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_covid_DetectAIProp_GPT4o_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\" AND topic LIKE \"covid\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_covid_DetectAIProp_GPT41.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\" AND topic LIKE \"covid\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_covid_DetectAIProp_GPT41_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\" AND topic LIKE \"covid\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_capitolriot_DetectAIProp_GPT35.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\" AND topic LIKE \"capitolriot\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_capitolriot_DetectAIProp_GPT35_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\" AND topic LIKE \"capitolriot\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_capitolriot_DetectAIProp_GPT4o.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\" AND topic LIKE \"capitolriot\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_capitolriot_DetectAIProp_GPT4o_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\" AND topic LIKE \"capitolriot\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_capitolriot_DetectAIProp_GPT41.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\" AND topic LIKE \"capitolriot\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_capitolriot_DetectAIProp_GPT41_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\" AND topic LIKE \"capitolriot\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_lgbt_DetectAIProp_GPT35.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\" AND topic LIKE \"lgbt\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_lgbt_DetectAIProp_GPT35_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-3.5-turbo\" AND topic LIKE \"lgbt\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_lgbt_DetectAIProp_GPT4o.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\" AND topic LIKE \"lgbt\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_lgbt_DetectAIProp_GPT4o_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4o\" AND topic LIKE \"lgbt\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "    \"models/LGBM_lgbt_DetectAIProp_GPT41.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\" AND topic LIKE \"lgbt\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"withPunc\"\n",
    "    },\n",
    "    \"models/LGBM_lgbt_DetectAIProp_GPT41_noPunc.pkl\": {\n",
    "        \"query\": 'SELECT * FROM ai_prop_liwc WHERE WC >= 100 AND model LIKE \"gpt-4.1\" AND topic LIKE \"lgbt\"',\n",
    "        \"target_variable\": \"Label\",\n",
    "        \"x_features\": \"noPunc\"\n",
    "    },\n",
    "}\n",
    "\n",
    "print(len(model_configs), \"models loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model you want to analyze by selecting a model path from model_configs\n",
    "model_path = 'models/LGBM_Combined_DetectAIProp_GPT41_noPunc.pkl'  \n",
    "query = model_configs[model_path]['query']\n",
    "target_variable = model_configs[model_path]['target_variable']  \n",
    "x_features = model_configs[model_path]['x_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute query and load results into pandas dataframe\n",
    "def execute_query_pandas(path, query):\n",
    "    \"\"\"Execute SQL query and return results as pandas DataFrame.\"\"\"\n",
    "    conn = sqlite3.connect(path)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "# Load the model from the .pkl file\n",
    "with open(model_path, 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "The data preparation process involves several steps:\n",
    "\n",
    "1. **Database Query**: Select relevant articles based on:\n",
    "   - Minimum word count (WC â‰¥ 100)\n",
    "   - Model type (human/AI)\n",
    "   - Topic (if applicable)\n",
    "\n",
    "2. **Feature Processing**:\n",
    "   - Remove non-LIWC features (metadata, text content)\n",
    "   - Optional removal of punctuation features\n",
    "   - Feature normalization to [0,1] range\n",
    "\n",
    "3. **Data Split**:\n",
    "   - 70% training / 30% testing\n",
    "   - Stratified sampling to maintain class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "path = f'ai_propaganda.db' #Assign the path to the database (assumes its in the same directory)\n",
    "\n",
    "data = execute_query_pandas(path,query)\n",
    "\n",
    "# The features to remove are selected based on the chosen model (with or without punctuation features)\n",
    "if x_features == \"withPunc\":\n",
    "    feature_columns = [\n",
    "                \"Analytic\", \"Clout\", \"Authentic\", \"Tone\", \"WPS\", \"BigWords\", \"Dic\", \"Linguistic\",\n",
    "                \"function\", \"pronoun\", \"ppron\", \"i\", \"we\", \"you\", \"shehe\", \"they\", \"ipron\", \"det\",\n",
    "                \"article\", \"number\", \"prep\", \"auxverb\", \"adverb\", \"conj\", \"negate\", \"verb\", \"adj\",\n",
    "                \"quantity\", \"Drives\", \"affiliation\", \"achieve\", \"power\", \"Cognition\", \"allnone\",\n",
    "                \"cogproc\", \"insight\", \"cause\", \"discrep\", \"tentat\", \"certitude\", \"differ\", \"memory\",\n",
    "                \"Affect\", \"tone_pos\", \"tone_neg\", \"emotion\", \"emo_pos\", \"emo_neg\", \"emo_anx\",\n",
    "                \"emo_anger\", \"emo_sad\", \"swear\", \"Social\", \"socbehav\", \"prosocial\", \"polite\", \"conflict\",\n",
    "                \"moral\", \"comm\", \"socrefs\", \"family\", \"friend\", \"female\", \"male\", \"Culture\", \"politic\",\n",
    "                \"ethnicity\", \"tech\", \"Lifestyle\", \"leisure\", \"home\", \"work\", \"money\", \"relig\",\n",
    "                \"Physical\", \"health\", \"illness\", \"wellness\", \"mental\", \"substances\", \"sexual\", \"food\",\n",
    "                \"death\", \"need\", \"want\", \"acquire\", \"lack\", \"fulfill\", \"fatigue\", \"reward\", \"risk\",\n",
    "                \"curiosity\", \"allure\", \"Perception\", \"attention\", \"motion\", \"space\", \"visual\",\n",
    "                \"auditory\", \"feeling\", \"time\", \"focuspast\", \"focuspresent\", \"focusfuture\",\n",
    "                \"Conversation\", \"netspeak\", \"assent\", \"nonflu\", \"filler\", \"AllPunc\", \"Period\", \"Comma\",\n",
    "                \"QMark\", \"Exclam\", \"Apostro\", \"OtherP\", \"Emoji\"\n",
    "            ]\n",
    "elif x_features == \"noPunc\":\n",
    "    feature_columns = [\n",
    "                \"Analytic\", \"Clout\", \"Authentic\", \"Tone\", \"WPS\", \"BigWords\", \"Dic\", \"Linguistic\",\n",
    "                \"function\", \"pronoun\", \"ppron\", \"i\", \"we\", \"you\", \"shehe\", \"they\", \"ipron\", \"det\",\n",
    "                \"article\", \"number\", \"prep\", \"auxverb\", \"adverb\", \"conj\", \"negate\", \"verb\", \"adj\",\n",
    "                \"quantity\", \"Drives\", \"affiliation\", \"achieve\", \"power\", \"Cognition\", \"allnone\",\n",
    "                \"cogproc\", \"insight\", \"cause\", \"discrep\", \"tentat\", \"certitude\", \"differ\", \"memory\",\n",
    "                \"Affect\", \"tone_pos\", \"tone_neg\", \"emotion\", \"emo_pos\", \"emo_neg\", \"emo_anx\",\n",
    "                \"emo_anger\", \"emo_sad\", \"swear\", \"Social\", \"socbehav\", \"prosocial\", \"polite\", \"conflict\",\n",
    "                \"moral\", \"comm\", \"socrefs\", \"family\", \"friend\", \"female\", \"male\", \"Culture\", \"politic\",\n",
    "                \"ethnicity\", \"tech\", \"Lifestyle\", \"leisure\", \"home\", \"work\", \"money\", \"relig\",\n",
    "                \"Physical\", \"health\", \"illness\", \"wellness\", \"mental\", \"substances\", \"sexual\", \"food\",\n",
    "                \"death\", \"need\", \"want\", \"acquire\", \"lack\", \"fulfill\", \"fatigue\", \"reward\", \"risk\",\n",
    "                \"curiosity\", \"allure\", \"Perception\", \"attention\", \"motion\", \"space\", \"visual\",\n",
    "                \"auditory\", \"feeling\", \"time\", \"focuspast\", \"focuspresent\", \"focusfuture\",\n",
    "                \"Conversation\", \"netspeak\", \"assent\", \"nonflu\", \"filler\", \"Emoji\"\n",
    "            ]\n",
    "else:\n",
    "    raise ValueError(\"Invalid x_features value. Please ensure you have selected a valid model path.\")\n",
    "\n",
    "X = data[feature_columns].copy()\n",
    "# X = data.drop(remove_feat_list, axis=1)\n",
    "y = data[target_variable]\n",
    "\n",
    "# Normalize feature values to range [0, 1]\n",
    "for column in X.columns:\n",
    "        #print(f'{column} has max of {X[column].max()}')\n",
    "        if X[column].max() == 0: #Check for columns that contain no LIWC values \n",
    "            print(f'Column {column} can be removed.')\n",
    "        X[column] = (X[column] - X[column].min()) / (X[column].max() - X[column].min())\n",
    "\n",
    "# Split data\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=test_size, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Performance Analysis\n",
    "\n",
    "The analysis includes comprehensive classification metrics:\n",
    "\n",
    "1. **Basic Metrics**:\n",
    "   - Accuracy: Overall prediction accuracy\n",
    "   - Precision: Accuracy of positive predictions\n",
    "   - Recall: Proportion of actual positives identified\n",
    "   - F1 Score: Harmonic mean of precision and recall\n",
    "\n",
    "2. **Advanced Metrics**:\n",
    "   - ROC-AUC: Area under ROC curve\n",
    "   - PR-AUC: Area under Precision-Recall curve\n",
    "   - Confusion Matrix Components\n",
    "\n",
    "3. **Class Distribution**:\n",
    "   - Prediction Rate: Proportion of positive predictions\n",
    "   - Positive Class Rate: Actual proportion of positive cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_metrics(y_test: np.ndarray, y_predicted: np.ndarray, prob: np.ndarray) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive classification metrics for model evaluation.\n",
    "    \n",
    "    Args:\n",
    "        y_test: Array of true labels\n",
    "        y_predicted: Array of predicted labels\n",
    "        prob: Array of prediction probabilities\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing various classification metrics:\n",
    "        - Basic metrics: Accuracy, Precision, Recall, F1\n",
    "        - Advanced metrics: ROC-AUC, PR-AUC\n",
    "        - Class distribution metrics: Prediction rates\n",
    "        - Confusion matrix components: TP, TN, FP, FN\n",
    "    \"\"\"\n",
    "    # Basic metrics\n",
    "    accuracy = round(accuracy_score(y_test, y_predicted), 2)\n",
    "    precision = round(precision_score(y_test, y_predicted), 2)\n",
    "    precision_0 = round(precision_score(y_test, y_predicted, pos_label=0), 2)\n",
    "    recall = round(recall_score(y_test, y_predicted), 2)\n",
    "    specificity = round(recall_score(y_test, y_predicted, pos_label=0), 2)\n",
    "    f1 = round(f1_score(y_test, y_predicted), 2)\n",
    "    f1_0 = round(f1_score(y_test, y_predicted, pos_label=0), 2)\n",
    "    \n",
    "    # AUC metrics\n",
    "    p, r, th = precision_recall_curve(y_test, prob)\n",
    "    pr_auc = round(auc(r, p), 2)\n",
    "    \n",
    "    if len(np.unique(y_test)) == 1:\n",
    "        roc = np.NaN\n",
    "    else:\n",
    "        roc = round(roc_auc_score(y_test, prob), 2)\n",
    "    \n",
    "    # Rates\n",
    "    pos_pred_rate = round(sum(y_predicted) * 100 / len(y_predicted), 2)\n",
    "    pos_rate = round(sum(y_test) * 100 / len(y_test), 2)\n",
    "    \n",
    "    # Confusion matrix components\n",
    "    temp = pd.DataFrame({'actual': y_test, 'prediction': y_predicted})\n",
    "    tp = len(temp[(temp['actual'] == 1) & (temp['prediction'] == 1)])\n",
    "    tn = len(temp[(temp['actual'] == 0) & (temp['prediction'] == 0)])\n",
    "    fp = len(temp[(temp['actual'] == 0) & (temp['prediction'] == 1)])\n",
    "    fn = len(temp[(temp['actual'] == 1) & (temp['prediction'] == 0)])\n",
    "    \n",
    "    metrics = {\n",
    "        'metrics': [\n",
    "            \"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"Precision_0\",\n",
    "            \"F1\", \"F1_0\", \"PR_AUC\", \"ROC\", \"TP\", \"FP\", \"TN\", \"FN\",\n",
    "            \"PredictionRate\", \"PositiveClassRate\", \"Count\"\n",
    "        ],\n",
    "        'value': [\n",
    "            accuracy, precision, recall, specificity, precision_0,\n",
    "            f1, f1_0, pr_auc, roc, tp, fp, tn, fn,\n",
    "            pos_pred_rate, pos_rate, len(y_test)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "def find_optimal_threshold(y_test: np.ndarray, y_pred_prob: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Find optimal classification threshold using Youden's J statistic\n",
    "    \n",
    "    Args:\n",
    "        y_test: True labels\n",
    "        y_pred_prob: Prediction probabilities\n",
    "        \n",
    "    Returns:\n",
    "        Optimal threshold value\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "    return threshold\n",
    "\n",
    "\n",
    "# Get model predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "threshold = find_optimal_threshold(y_test, y_pred_prob)\n",
    "y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "\n",
    "# Calculate and display metrics\n",
    "metrics_df = get_classification_metrics(y_test, y_pred, y_pred_prob)\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "print(\"=\"*50)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SHAP Analysis\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) analysis reveals how each feature contributes to the model's predictions.\n",
    "\n",
    "To save plots, uncomment the `plt.savefig()` lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# Enables interactive plots to open in a separate window, which allows for zooming, panning, and resizing.\n",
    "# Requires the PyQt6 package to be installed as the backend for rendering the window.\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Plots\n",
    "\n",
    "1. **Beeswarm Plot**:\n",
    "   - Shows feature importance distribution\n",
    "   - Red = high feature values\n",
    "   - Blue = low feature values\n",
    "   - Horizontal spread = SHAP value impact\n",
    "\n",
    "2. **Bar Plot**:\n",
    "   - Average magnitude of feature importance\n",
    "   - Helps identify top contributing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.summary_plot(shap_values, X, max_display=10)\n",
    "\n",
    "# Get the current figure and axes objects. from @GarrettCGraham code\n",
    "fig, ax = plt.gcf(), plt.gca()\n",
    "\n",
    "# Modifying main plot parameters\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_xlabel(\"SHAP value (impact on model output)\", fontsize=12)\n",
    "\n",
    "# Get colorbar\n",
    "cb_ax = fig.axes[1] \n",
    "\n",
    "# Modifying color bar parameters\n",
    "cb_ax.tick_params(labelsize=14)\n",
    "cb_ax.set_ylabel(\"Feature value\", fontsize=12)\n",
    "\n",
    "ax.yaxis.grid(linestyle='--', linewidth='.6', color='grey')\n",
    "\n",
    "ax.tick_params(axis='x', colors='black')\n",
    "ax.tick_params(axis='y', colors='black')\n",
    "\n",
    "# Uncomment below to save the plot\n",
    "# plt.savefig('SHAP_Top_10_Beeswarm.png',format = \"png\",dpi = 300,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_plot = shap.summary_plot(shap_values, X, plot_type=\"bar\", color='#9fb2d1',max_display=10)\n",
    "ax = plt.gca()\n",
    "ax.tick_params(labelsize=12)\n",
    "\n",
    "ax.xaxis.label.set_fontsize(12)\n",
    "ax.yaxis.grid(linestyle='--', linewidth='0.6', color='grey')\n",
    "ax.tick_params(axis='y', labelsize=16, colors='black')  # Increase Y-axis label size\n",
    "\n",
    "# Uncomment below to save the plot\n",
    "# plt.savefig('SHAP_Top_10_Barplot.png',format = \"png\",dpi = 300,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Dependence Analysis\n",
    "\n",
    "Examines relationships between:\n",
    "- Individual feature values and their SHAP values\n",
    "- Interactions between feature pairs\n",
    "- Specific combinations of linguistic features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, create a SHAP dependence plot for specific features\n",
    "features = [\"WPS\", \"BigWords\"]\n",
    "\n",
    "for feature_name in features:\n",
    "    dep_plot = shap.dependence_plot(feature_name, shap_values, X) #Automatically chooses interaction\n",
    "    #shap.dependence_plot('work', shap_values, X, interaction_index='we')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.label.set_fontsize(13)\n",
    "    ax.yaxis.label.set_fontsize(13)\n",
    "\n",
    "    cbar = plt.gcf().get_axes()[-1]  # Get the color bar axis\n",
    "    print(\"Color bar label font size:\", cbar.yaxis.label.get_size())\n",
    "\n",
    "    # Uncomment below to save the plot\n",
    "    # plt.savefig(f'SHAP_{feature_name}_Dependence.png',format = \"png\",dpi = 300,bbox_inches = 'tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific Dependence Plot Combos\n",
    "combos = [(\"Cognition\",\"Analytic\"), (\"we\",\"moral\")]\n",
    "\n",
    "for combo in combos:\n",
    "    dep_plot = shap.dependence_plot(combo[0], shap_values, X, interaction_index=combo[1])\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.label.set_fontsize(13)\n",
    "    ax.yaxis.label.set_fontsize(13)\n",
    "\n",
    "    cbar = plt.gcf().get_axes()[-1]  # Get the color bar axis\n",
    "    #print(\"Color bar label font size:\", cbar.yaxis.label.get_size())\n",
    "\n",
    "    # Uncomment below to save the plot\n",
    "    # plt.savefig(f'SHAP_{combo[0]}_and_{combo[1]}_Dependence.png',format = \"png\",dpi = 300,bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propaganda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
